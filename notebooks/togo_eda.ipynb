{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7969b80c",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis for Solar Data Discovery Challenge (Togo Dataset)\n",
    "\n",
    "This notebook performs data profiling, cleaning, and exploratory data analysis (EDA) on the Togo solar radiation dataset (`data/togo-dapaong_qc.csv`). It is designed for modularity and reusability, enabling analysis of Benin and Sierra Leone datasets by updating the configuration. The script addresses feedback on:\n",
    "\n",
    "- **Code modularity**: Organized into functions for loading, profiling, cleaning, and EDA.\n",
    "- **Reusability**: Configuration dictionary for dataset-specific parameters.\n",
    "- **Documentation**: Comprehensive docstrings and comments.\n",
    "- **Version control**: Demonstrated through Git commits and PRs.\n",
    "- **Advanced functionality**: Plans for cross-country comparison and dashboard development.\n",
    "\n",
    "**Outputs**:\n",
    "- Cleaned dataset: `data/togo_clean.csv`\n",
    "- Visualizations: `data/plots/` (time series, correlation heatmap, wind rose, bubble chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6884c464",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c34920f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for data processing and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from windrose import WindroseAxes \n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7790d577",
   "metadata": {},
   "source": [
    "Setting the country name and creating the data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e8efca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration dictionary for reusability across datasets\n",
    "CONFIG = {\n",
    "    'country': 'togo',\n",
    "    'raw_data_file': '../data/togo-dapaong_qc.csv',\n",
    "    'cleaned_data_file': 'data/togo_clean.csv',\n",
    "    'numeric_cols': ['GHI', 'DNI', 'DHI', 'ModA', 'ModB', 'Tamb', 'RH', 'WS', 'WSgust', 'WD', 'TModA', 'TModB'],\n",
    "    'irradiance_cols': ['GHI', 'DNI', 'DHI', 'ModA', 'ModB']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c548f63",
   "metadata": {},
   "source": [
    "Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4994c91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load dataset from CSV, validating file existence and timestamp format.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the raw CSV file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Loaded dataset with parsed timestamps.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the CSV file does not exist.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Dataset not found at {file_path}\")\n",
    "    df = pd.read_csv(file_path, parse_dates=['Timestamp'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85db7591",
   "metadata": {},
   "source": [
    "Profile Data Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb583744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_data(df: pd.DataFrame) -> dict:\n",
    "    \"\"\"Profile dataset, computing statistics, missing values, and quality issues.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataset.\n",
    "\n",
    "    Returns:\n",
    "        dict: Profiling results (statistics, missing values, negative counts).\n",
    "    \"\"\"\n",
    "    # Summary statistics for all columns\n",
    "    stats_summary = df.describe(include='all')\n",
    "    \n",
    "    # Missing values count and percentage\n",
    "    missing_counts = df.isna().sum()\n",
    "    missing_percent = (missing_counts / len(df) * 100).round(2)\n",
    "    \n",
    "    # Count negative values in irradiance columns\n",
    "    negative_counts = {col: (df[col] < 0).sum() for col in CONFIG['irradiance_cols']}\n",
    "    \n",
    "    # Count outliers (Z-scores > 3) in numeric columns\n",
    "    outlier_counts = {}\n",
    "    for col in CONFIG['numeric_cols']:\n",
    "        if col in df.columns:\n",
    "            z_scores = np.abs(stats.zscore(df[col].dropna()))\n",
    "            outlier_counts[col] = (z_scores > 3).sum()\n",
    "    \n",
    "    return {\n",
    "        'statistics': stats_summary,\n",
    "        'missing_counts': missing_counts,\n",
    "        'missing_percent': missing_percent,\n",
    "        'negative_counts': negative_counts,\n",
    "        'outlier_counts': outlier_counts\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2219a06b",
   "metadata": {},
   "source": [
    "Cleaning data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4440efa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Clean dataset by handling negative values, missing data, and outliers.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataset.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned dataset with outlier flags.\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Clip negative irradiance values to 0\n",
    "    for col in CONFIG['irradiance_cols']:\n",
    "        if col in df_clean.columns:\n",
    "            df_clean[col] = np.maximum(df_clean[col], 0)\n",
    "    \n",
    "    # Impute missing numeric values with median\n",
    "    for col in CONFIG['numeric_cols']:\n",
    "        if col in df_clean.columns and df_clean[col].isna().any():\n",
    "            df_clean[col] = df_clean[col].fillna(df_clean[col].median())\n",
    "    \n",
    "    # Drop rows with missing Timestamp\n",
    "    df_clean = df_clean.dropna(subset=['Timestamp'])\n",
    "    \n",
    "    # Flag outliers (Z-scores > 3)\n",
    "    df_clean['outlier_flag'] = False\n",
    "    for col in CONFIG['numeric_cols']:\n",
    "        if col in df_clean.columns:\n",
    "            z_scores = np.abs(stats.zscore(df_clean[col]))\n",
    "            df_clean['outlier_flag'] |= (z_scores > 3)\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6678ba",
   "metadata": {},
   "source": [
    "Perform EDA function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7efd676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_eda(df: pd.DataFrame, output_dir: str):\n",
    "    \"\"\"Perform EDA, generating visualizations for time series, correlations, wind, and relationships.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Cleaned dataset.\n",
    "        output_dir (str): Directory to save plots.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Time Series Plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for col in ['GHI', 'DNI', 'DHI', 'Tamb']:\n",
    "        if col in df.columns:\n",
    "            plt.plot(df['Timestamp'], df[col], label=col)\n",
    "    plt.title('Time Series of Irradiance and Temperature')\n",
    "    plt.xlabel('Timestamp')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{output_dir}/time_series.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Correlation Heatmap\n",
    "    corr_cols = ['GHI', 'DNI', 'DHI', 'TModA', 'TModB']\n",
    "    if all(col in df.columns for col in corr_cols):\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(df[corr_cols].corr(), annot=True, cmap='coolwarm')\n",
    "        plt.title('Correlation Matrix')\n",
    "        plt.savefig(f'{output_dir}/correlation_heatmap.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # Wind Rose\n",
    "    if 'WS' in df.columns and 'WD' in df.columns:\n",
    "        fig = plt.figure(figsize=(8, 8))\n",
    "        ax = WindroseAxes.from_ax(fig=fig)\n",
    "        ax.bar(df['WD'], df['WS'], normed=True, opening=0.8, edgecolor='white')\n",
    "        ax.set_legend()\n",
    "        plt.title('Wind Rose Plot')\n",
    "        plt.savefig(f'{output_dir}/wind_rose.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # Bubble Chart (GHI vs Tamb, sized by RH)\n",
    "    if all(col in df.columns for col in ['GHI', 'Tamb', 'RH']):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(df['Tamb'], df['GHI'], s=df['RH']*10, c=df['RH'], cmap='viridis', alpha=0.5)\n",
    "        plt.colorbar(label='Relative Humidity (%)')\n",
    "        plt.xlabel('Ambient Temperature (°C)')\n",
    "        plt.ylabel('GHI (W/m²)')\n",
    "        plt.title('GHI vs Temperature (Bubble Size/Color by RH)')\n",
    "        plt.savefig(f'{output_dir}/bubble_chart.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246cb9b6",
   "metadata": {},
   "source": [
    "TIme series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4955ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiling Results:\n",
      "Statistics:\n",
      "                            Timestamp            GHI            DNI  \\\n",
      "count                         525600  525600.000000  525600.000000   \n",
      "mean   2022-04-25 12:00:30.000000768     230.555040     151.258469   \n",
      "min              2021-10-25 00:01:00     -12.700000       0.000000   \n",
      "25%              2022-01-24 06:00:45      -2.200000       0.000000   \n",
      "50%              2022-04-25 12:00:30       2.100000       0.000000   \n",
      "75%              2022-07-25 18:00:15     442.400000     246.400000   \n",
      "max              2022-10-25 00:00:00    1424.000000    1004.500000   \n",
      "std                              NaN     322.532347     250.956962   \n",
      "\n",
      "                 DHI           ModA           ModB           Tamb  \\\n",
      "count  525600.000000  525600.000000  525600.000000  525600.000000   \n",
      "mean      116.444352     226.144375     219.568588      27.751788   \n",
      "min         0.000000       0.000000       0.000000      14.900000   \n",
      "25%         0.000000       0.000000       0.000000      24.200000   \n",
      "50%         2.500000       4.400000       4.300000      27.200000   \n",
      "75%       215.700000     422.525000     411.000000      31.100000   \n",
      "max       805.700000    1380.000000    1367.000000      41.400000   \n",
      "std       156.520714     317.346938     307.932510       4.758023   \n",
      "\n",
      "                  RH             WS         WSgust        WSstdev  \\\n",
      "count  525600.000000  525600.000000  525600.000000  525600.000000   \n",
      "mean       55.013160       2.368093       3.229490       0.557740   \n",
      "min         3.300000       0.000000       0.000000       0.000000   \n",
      "25%        26.500000       1.400000       1.900000       0.400000   \n",
      "50%        59.300000       2.200000       2.900000       0.500000   \n",
      "75%        80.800000       3.200000       4.400000       0.700000   \n",
      "max        99.800000      16.100000      23.100000       4.700000   \n",
      "std        28.778732       1.462668       1.882565       0.268923   \n",
      "\n",
      "                  WD        WDstdev             BP       Cleaning  \\\n",
      "count  525600.000000  525600.000000  525600.000000  525600.000000   \n",
      "mean      161.741845      10.559568     975.915242       0.000535   \n",
      "min         0.000000       0.000000     968.000000       0.000000   \n",
      "25%        74.800000       6.900000     975.000000       0.000000   \n",
      "50%       199.100000      10.800000     976.000000       0.000000   \n",
      "75%       233.500000      14.100000     977.000000       0.000000   \n",
      "max       360.000000      86.900000     983.000000       1.000000   \n",
      "std        91.877217       5.915490       2.153977       0.023116   \n",
      "\n",
      "       Precipitation          TModA          TModB  Comments  \n",
      "count  525600.000000  525600.000000  525600.000000       0.0  \n",
      "mean        0.001382      32.444403      33.543330       NaN  \n",
      "min         0.000000      13.100000      13.100000       NaN  \n",
      "25%         0.000000      23.900000      23.600000       NaN  \n",
      "50%         0.000000      28.400000      28.400000       NaN  \n",
      "75%         0.000000      40.600000      43.000000       NaN  \n",
      "max         2.300000      70.400000      94.600000       NaN  \n",
      "std         0.026350      10.998334      12.769277       NaN  \n",
      "Missing Values:\n",
      " Timestamp             0\n",
      "GHI                   0\n",
      "DNI                   0\n",
      "DHI                   0\n",
      "ModA                  0\n",
      "ModB                  0\n",
      "Tamb                  0\n",
      "RH                    0\n",
      "WS                    0\n",
      "WSgust                0\n",
      "WSstdev               0\n",
      "WD                    0\n",
      "WDstdev               0\n",
      "BP                    0\n",
      "Cleaning              0\n",
      "Precipitation         0\n",
      "TModA                 0\n",
      "TModB                 0\n",
      "Comments         525600\n",
      "dtype: int64\n",
      "Negative Counts:\n",
      " {'GHI': np.int64(257385), 'DNI': np.int64(0), 'DHI': np.int64(0), 'ModA': np.int64(0), 'ModB': np.int64(0)}\n",
      "Outlier Counts:\n",
      " {'GHI': np.int64(305), 'DNI': np.int64(1062), 'DHI': np.int64(3415), 'ModA': np.int64(137), 'ModB': np.int64(206), 'Tamb': np.int64(0), 'RH': np.int64(0), 'WS': np.int64(3510), 'WSgust': np.int64(3915), 'WD': np.int64(0), 'TModA': np.int64(153), 'TModB': np.int64(609)}\n",
      "EDA completed. Outputs saved in data/ directory.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Execute the EDA pipeline for the configured dataset.\"\"\"\n",
    "    try:\n",
    "        # Load data\n",
    "        df = load_data(CONFIG['raw_data_file'])\n",
    "        \n",
    "        # Profile data\n",
    "        profile = profile_data(df)\n",
    "        print(\"Profiling Results:\")\n",
    "        print(\"Statistics:\\n\", profile['statistics'])\n",
    "        print(\"Missing Values:\\n\", profile['missing_counts'])\n",
    "        print(\"Negative Counts:\\n\", profile['negative_counts'])\n",
    "        print(\"Outlier Counts:\\n\", profile['outlier_counts'])\n",
    "        \n",
    "        # Clean data\n",
    "        df_clean = clean_data(df)\n",
    "        \n",
    "        # Save cleaned data\n",
    "        os.makedirs(os.path.dirname(CONFIG['cleaned_data_file']), exist_ok=True)\n",
    "        df_clean.to_csv(CONFIG['cleaned_data_file'], index=False)\n",
    "        \n",
    "        # Perform EDA\n",
    "        perform_eda(df_clean, 'data/plots')\n",
    "        \n",
    "        print(\"EDA completed. Outputs saved in data/ directory.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "\n",
    "# Run the pipeline\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
