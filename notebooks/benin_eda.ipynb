{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d52f5898",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis for Solar Data Discovery Challenge (Benin Dataset)\n",
    "\n",
    "This notebook performs data profiling, cleaning, and exploratory data analysis (EDA) on the Benin solar radiation dataset (`data/benin-qc.csv`). It is designed for modularity and reusability, enabling analysis of Togo and Sierra Leone datasets by updating the configuration. The script addresses feedback on:\n",
    "\n",
    "- **Code modularity**: Organized into functions for loading, profiling, cleaning, and EDA.\n",
    "- **Reusability**: Configuration dictionary for dataset-specific parameters.\n",
    "- **Documentation**: Comprehensive docstrings and comments.\n",
    "- **Version control**: Demonstrated through Git commits and PRs.\n",
    "- **Advanced functionality**: Plans for cross-country comparison and dashboard development.\n",
    "\n",
    "**Outputs**:\n",
    "- Cleaned dataset: `data/benin_clean.csv`\n",
    "- Visualizations: `data/plots/` (time series, correlation heatmap, wind rose, bubble chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057a87a6",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d994050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for data processing and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from windrose import WindroseAxes\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5668427",
   "metadata": {},
   "source": [
    "Setting the country name and creating the data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "305cd685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration dictionary for reusability across datasets\n",
    "CONFIG = {\n",
    "    'country': 'benin',\n",
    "    'raw_data_file': '../data/benin-malanville.csv',\n",
    "    'cleaned_data_file': 'data/benin_clean.csv',\n",
    "    'numeric_cols': ['GHI', 'DNI', 'DHI', 'ModA', 'ModB', 'Tamb', 'RH', 'WS', 'WSgust', 'WD', 'TModA', 'TModB'],\n",
    "    'irradiance_cols': ['GHI', 'DNI', 'DHI', 'ModA', 'ModB']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3861615",
   "metadata": {},
   "source": [
    "Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3ed2c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load dataset from CSV, validating file existence and timestamp format.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the raw CSV file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Loaded dataset with parsed timestamps.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the CSV file does not exist.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Dataset not found at {file_path}\")\n",
    "    df = pd.read_csv(file_path, parse_dates=['Timestamp'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e88710a",
   "metadata": {},
   "source": [
    "Profile Data Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e0e775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_data(df: pd.DataFrame) -> dict:\n",
    "    \"\"\"Profile dataset, computing statistics, missing values, and quality issues.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataset.\n",
    "\n",
    "    Returns:\n",
    "        dict: Profiling results (statistics, missing values, negative counts).\n",
    "    \"\"\"\n",
    "    # Summary statistics for all columns\n",
    "    stats_summary = df.describe(include='all')\n",
    "    \n",
    "    # Missing values count and percentage\n",
    "    missing_counts = df.isna().sum()\n",
    "    missing_percent = (missing_counts / len(df) * 100).round(2)\n",
    "    \n",
    "    # Count negative values in irradiance columns\n",
    "    negative_counts = {col: (df[col] < 0).sum() for col in CONFIG['irradiance_cols']}\n",
    "    \n",
    "    # Count outliers (Z-scores > 3) in numeric columns\n",
    "    outlier_counts = {}\n",
    "    for col in CONFIG['numeric_cols']:\n",
    "        if col in df.columns:\n",
    "            z_scores = np.abs(stats.zscore(df[col].dropna()))\n",
    "            outlier_counts[col] = (z_scores > 3).sum()\n",
    "    \n",
    "    return {\n",
    "        'statistics': stats_summary,\n",
    "        'missing_counts': missing_counts,\n",
    "        'missing_percent': missing_percent,\n",
    "        'negative_counts': negative_counts,\n",
    "        'outlier_counts': outlier_counts\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7319873",
   "metadata": {},
   "source": [
    "Profile data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b340163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_data(df: pd.DataFrame) -> dict:\n",
    "    \"\"\"Profile dataset, computing statistics, missing values, and quality issues.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataset.\n",
    "\n",
    "    Returns:\n",
    "        dict: Profiling results (statistics, missing values, negative counts).\n",
    "    \"\"\"\n",
    "    # Summary statistics for all columns\n",
    "    stats_summary = df.describe(include='all')\n",
    "    \n",
    "    # Missing values count and percentage\n",
    "    missing_counts = df.isna().sum()\n",
    "    missing_percent = (missing_counts / len(df) * 100).round(2)\n",
    "    \n",
    "    # Count negative values in irradiance columns\n",
    "    negative_counts = {col: (df[col] < 0).sum() for col in CONFIG['irradiance_cols']}\n",
    "    \n",
    "    # Count outliers (Z-scores > 3) in numeric columns\n",
    "    outlier_counts = {}\n",
    "    for col in CONFIG['numeric_cols']:\n",
    "        if col in df.columns:\n",
    "            z_scores = np.abs(stats.zscore(df[col].dropna()))\n",
    "            outlier_counts[col] = (z_scores > 3).sum()\n",
    "    \n",
    "    return {\n",
    "        'statistics': stats_summary,\n",
    "        'missing_counts': missing_counts,\n",
    "        'missing_percent': missing_percent,\n",
    "        'negative_counts': negative_counts,\n",
    "        'outlier_counts': outlier_counts\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb8e8cd",
   "metadata": {},
   "source": [
    "Clean Data Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec09b095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Clean dataset by handling negative values, missing data, and outliers.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataset.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned dataset with outlier flags.\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Clip negative irradiance values to 0\n",
    "    for col in CONFIG['irradiance_cols']:\n",
    "        if col in df_clean.columns:\n",
    "            df_clean[col] = np.maximum(df_clean[col], 0)\n",
    "    \n",
    "    # Impute missing numeric values with median\n",
    "    for col in CONFIG['numeric_cols']:\n",
    "        if col in df_clean.columns and df_clean[col].isna().any():\n",
    "            df_clean[col] = df_clean[col].fillna(df_clean[col].median())\n",
    "    \n",
    "    # Drop rows with missing Timestamp\n",
    "    df_clean = df_clean.dropna(subset=['Timestamp'])\n",
    "    \n",
    "    # Flag outliers (Z-scores > 3)\n",
    "    df_clean['outlier_flag'] = False\n",
    "    for col in CONFIG['numeric_cols']:\n",
    "        if col in df_clean.columns:\n",
    "            z_scores = np.abs(stats.zscore(df_clean[col]))\n",
    "            df_clean['outlier_flag'] |= (z_scores > 3)\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e67c863",
   "metadata": {},
   "source": [
    "Perform EDA Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14c8e6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_eda(df: pd.DataFrame, output_dir: str):\n",
    "    \"\"\"Perform EDA, generating visualizations for time series, correlations, wind, and relationships.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Cleaned dataset.\n",
    "        output_dir (str): Directory to save plots.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Time Series Plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for col in ['GHI', 'DNI', 'DHI', 'Tamb']:\n",
    "        if col in df.columns:\n",
    "            plt.plot(df['Timestamp'], df[col], label=col)\n",
    "    plt.title(f'Time Series of Irradiance and Temperature ({CONFIG[\"country\"].capitalize()})')\n",
    "    plt.xlabel('Timestamp')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend(loc='upper right')  # Explicitly set legend location to avoid warning\n",
    "    plt.savefig(f'{output_dir}/time_series_{CONFIG[\"country\"]}.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Correlation Heatmap\n",
    "    corr_cols = ['GHI', 'DNI', 'DHI', 'TModA', 'TModB']\n",
    "    if all(col in df.columns for col in corr_cols):\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(df[corr_cols].corr(), annot=True, cmap='coolwarm')\n",
    "        plt.title(f'Correlation Matrix ({CONFIG[\"country\"].capitalize()})')\n",
    "        plt.savefig(f'{output_dir}/correlation_heatmap_{CONFIG[\"country\"]}.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # Wind Rose\n",
    "    if 'WS' in df.columns and 'WD' in df.columns:\n",
    "        fig = plt.figure(figsize=(8, 8))\n",
    "        ax = WindroseAxes.from_ax(fig=fig)\n",
    "        ax.bar(df['WD'], df['WS'], normed=True, opening=0.8, edgecolor='white')\n",
    "        ax.set_legend()\n",
    "        plt.title(f'Wind Rose Plot ({CONFIG[\"country\"].capitalize()})')\n",
    "        plt.savefig(f'{output_dir}/wind_rose_{CONFIG[\"country\"]}.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # Bubble Chart (GHI vs Tamb, sized by RH)\n",
    "    if all(col in df.columns for col in ['GHI', 'Tamb', 'RH']):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(df['Tamb'], df['GHI'], s=df['RH']*10, c=df['RH'], cmap='viridis', alpha=0.5)\n",
    "        plt.colorbar(label='Relative Humidity (%)')\n",
    "        plt.xlabel('Ambient Temperature (°C)')\n",
    "        plt.ylabel('GHI (W/m²)')\n",
    "        plt.title(f'GHI vs Temperature (Bubble Size/Color by RH) ({CONFIG[\"country\"].capitalize()})')\n",
    "        plt.savefig(f'{output_dir}/bubble_chart_{CONFIG[\"country\"]}.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee715b3",
   "metadata": {},
   "source": [
    "Main execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cf494a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiling Results (Benin):\n",
      "Statistics:\n",
      "                            Timestamp            GHI            DNI  \\\n",
      "count                         525600  525600.000000  525600.000000   \n",
      "mean   2022-02-07 12:00:30.000000512     240.559452     167.187516   \n",
      "min              2021-08-09 00:01:00     -12.900000      -7.800000   \n",
      "25%              2021-11-08 06:00:45      -2.000000      -0.500000   \n",
      "50%              2022-02-07 12:00:30       1.800000      -0.100000   \n",
      "75%              2022-05-09 18:00:15     483.400000     314.200000   \n",
      "max              2022-08-09 00:00:00    1413.000000     952.300000   \n",
      "std                              NaN     331.131327     261.710501   \n",
      "\n",
      "                 DHI           ModA           ModB           Tamb  \\\n",
      "count  525600.000000  525600.000000  525600.000000  525600.000000   \n",
      "mean      115.358961     236.589496     228.883576      28.179683   \n",
      "min       -12.600000       0.000000       0.000000      11.000000   \n",
      "25%        -2.100000       0.000000       0.000000      24.200000   \n",
      "50%         1.600000       4.500000       4.300000      28.000000   \n",
      "75%       216.300000     463.700000     447.900000      32.300000   \n",
      "max       759.200000    1342.300000    1342.300000      43.800000   \n",
      "std       158.691074     326.894859     316.536515       5.924297   \n",
      "\n",
      "                  RH             WS         WSgust        WSstdev  \\\n",
      "count  525600.000000  525600.000000  525600.000000  525600.000000   \n",
      "mean       54.487969       2.121113       2.809195       0.473390   \n",
      "min         2.100000       0.000000       0.000000       0.000000   \n",
      "25%        28.800000       1.000000       1.300000       0.400000   \n",
      "50%        55.100000       1.900000       2.600000       0.500000   \n",
      "75%        80.100000       3.100000       4.100000       0.600000   \n",
      "max       100.000000      19.500000      26.600000       4.200000   \n",
      "std        28.073069       1.603466       2.029120       0.273395   \n",
      "\n",
      "                  WD        WDstdev             BP       Cleaning  \\\n",
      "count  525600.000000  525600.000000  525600.000000  525600.000000   \n",
      "mean      153.435172       8.582407     994.197199       0.000923   \n",
      "min         0.000000       0.000000     985.000000       0.000000   \n",
      "25%        59.000000       3.700000     993.000000       0.000000   \n",
      "50%       181.000000       8.600000     994.000000       0.000000   \n",
      "75%       235.100000      12.300000     996.000000       0.000000   \n",
      "max       360.000000      99.400000    1003.000000       1.000000   \n",
      "std       102.332842       6.385864       2.474993       0.030363   \n",
      "\n",
      "       Precipitation          TModA          TModB  Comments  \n",
      "count  525600.000000  525600.000000  525600.000000       0.0  \n",
      "mean        0.001905      35.246026      32.471736       NaN  \n",
      "min         0.000000       9.000000       8.100000       NaN  \n",
      "25%         0.000000      24.200000      23.600000       NaN  \n",
      "50%         0.000000      30.000000      28.900000       NaN  \n",
      "75%         0.000000      46.900000      41.500000       NaN  \n",
      "max         2.500000      81.000000      72.500000       NaN  \n",
      "std         0.037115      14.807258      12.348743       NaN  \n",
      "Missing Values:\n",
      " Timestamp             0\n",
      "GHI                   0\n",
      "DNI                   0\n",
      "DHI                   0\n",
      "ModA                  0\n",
      "ModB                  0\n",
      "Tamb                  0\n",
      "RH                    0\n",
      "WS                    0\n",
      "WSgust                0\n",
      "WSstdev               0\n",
      "WD                    0\n",
      "WDstdev               0\n",
      "BP                    0\n",
      "Cleaning              0\n",
      "Precipitation         0\n",
      "TModA                 0\n",
      "TModB                 0\n",
      "Comments         525600\n",
      "dtype: int64\n",
      "Negative Counts:\n",
      " {'GHI': np.int64(258847), 'DNI': np.int64(275987), 'DHI': np.int64(259182), 'ModA': np.int64(0), 'ModB': np.int64(0)}\n",
      "Outlier Counts:\n",
      " {'GHI': np.int64(89), 'DNI': np.int64(0), 'DHI': np.int64(3738), 'ModA': np.int64(27), 'ModB': np.int64(63), 'Tamb': np.int64(0), 'RH': np.int64(0), 'WS': np.int64(3109), 'WSgust': np.int64(3500), 'WD': np.int64(0), 'TModA': np.int64(10), 'TModB': np.int64(98)}\n",
      "EDA completed for Benin. Outputs saved in data/ directory.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Execute the EDA pipeline for the configured dataset.\"\"\"\n",
    "    try:\n",
    "        # Load data\n",
    "        df = load_data(CONFIG['raw_data_file'])\n",
    "        \n",
    "        # Profile data\n",
    "        profile = profile_data(df)\n",
    "        print(f\"Profiling Results ({CONFIG['country'].capitalize()}):\")\n",
    "        print(\"Statistics:\\n\", profile['statistics'])\n",
    "        print(\"Missing Values:\\n\", profile['missing_counts'])\n",
    "        print(\"Negative Counts:\\n\", profile['negative_counts'])\n",
    "        print(\"Outlier Counts:\\n\", profile['outlier_counts'])\n",
    "        \n",
    "        # Clean data\n",
    "        df_clean = clean_data(df)\n",
    "        \n",
    "        # Save cleaned data\n",
    "        os.makedirs(os.path.dirname(CONFIG['cleaned_data_file']), exist_ok=True)\n",
    "        df_clean.to_csv(CONFIG['cleaned_data_file'], index=False)\n",
    "        \n",
    "        # Perform EDA\n",
    "        perform_eda(df_clean, 'data/plots')\n",
    "        \n",
    "        print(f\"EDA completed for {CONFIG['country'].capitalize()}. Outputs saved in data/ directory.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "\n",
    "# Run the pipeline\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
