{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94a73372",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis for Solar Data Discovery Challenge (Sierra Leone Dataset)\n",
    "\n",
    "This notebook performs data profiling, cleaning, and exploratory data analysis (EDA) on the Sierra Leone solar radiation dataset (`data/sierraleone-qc.csv`). It is designed for modularity and reusability, enabling analysis of Togo and Benin datasets by updating the configuration. The script addresses feedback on:\n",
    "\n",
    "- **Code modularity**: Organized into functions for loading, profiling, cleaning, and EDA.\n",
    "- **Reusability**: Configuration dictionary for dataset-specific parameters.\n",
    "- **Documentation**: Comprehensive docstrings and comments.\n",
    "- **Version control**: Demonstrated through Git commits and PRs.\n",
    "- **Advanced functionality**: Plans for cross-country comparison and dashboard development.\n",
    "\n",
    "**Outputs**:\n",
    "- Cleaned dataset: `data/sierraleone_clean.csv`\n",
    "- Visualizations: `data/plots/` (time series, correlation heatmap, wind rose, bubble chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8be6666",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f8d4506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for data processing and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from windrose import WindroseAxes\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c142aebf",
   "metadata": {},
   "source": [
    "Setting the country name and creating the data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "687d932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration dictionary for reusability across datasets\n",
    "CONFIG = {\n",
    "    'country': 'sierraleone',\n",
    "    'raw_data_file': '../data/sierraleone-bumbuna.csv',\n",
    "    'cleaned_data_file': './data/sierraleone_clean.csv',\n",
    "    'numeric_cols': ['GHI', 'DNI', 'DHI', 'ModA', 'ModB', 'Tamb', 'RH', 'WS', 'WSgust', 'WD', 'TModA', 'TModB'],\n",
    "    'irradiance_cols': ['GHI', 'DNI', 'DHI', 'ModA', 'ModB']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa82159",
   "metadata": {},
   "source": [
    "Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c16d6c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load dataset from CSV, validating file existence and timestamp format.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the raw CSV file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Loaded dataset with parsed timestamps.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the CSV file does not exist.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Dataset not found at {file_path}\")\n",
    "    df = pd.read_csv(file_path, parse_dates=['Timestamp'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b2aa24",
   "metadata": {},
   "source": [
    "Profile Data Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f335f533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_data(df: pd.DataFrame) -> dict:\n",
    "    \"\"\"Profile dataset, computing statistics, missing values, and quality issues.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataset.\n",
    "\n",
    "    Returns:\n",
    "        dict: Profiling results (statistics, missing values, negative counts).\n",
    "    \"\"\"\n",
    "    # Summary statistics for all columns\n",
    "    stats_summary = df.describe(include='all')\n",
    "    \n",
    "    # Missing values count and percentage\n",
    "    missing_counts = df.isna().sum()\n",
    "    missing_percent = (missing_counts / len(df) * 100).round(2)\n",
    "    \n",
    "    # Count negative values in irradiance columns\n",
    "    negative_counts = {col: (df[col] < 0).sum() for col in CONFIG['irradiance_cols']}\n",
    "    \n",
    "    # Count outliers (Z-scores > 3) in numeric columns\n",
    "    outlier_counts = {}\n",
    "    for col in CONFIG['numeric_cols']:\n",
    "        if col in df.columns:\n",
    "            z_scores = np.abs(stats.zscore(df[col].dropna()))\n",
    "            outlier_counts[col] = (z_scores > 3).sum()\n",
    "    \n",
    "    return {\n",
    "        'statistics': stats_summary,\n",
    "        'missing_counts': missing_counts,\n",
    "        'missing_percent': missing_percent,\n",
    "        'negative_counts': negative_counts,\n",
    "        'outlier_counts': outlier_counts\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83d2284",
   "metadata": {},
   "source": [
    "Cleaning data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db65bff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Clean dataset by handling negative values, missing data, and outliers.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataset.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned dataset with outlier flags.\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Clip negative irradiance values to 0\n",
    "    for col in CONFIG['irradiance_cols']:\n",
    "        if col in df_clean.columns:\n",
    "            df_clean[col] = np.maximum(df_clean[col], 0)\n",
    "    \n",
    "    # Impute missing numeric values with median\n",
    "    for col in CONFIG['numeric_cols']:\n",
    "        if col in df_clean.columns and df_clean[col].isna().any():\n",
    "            df_clean[col] = df_clean[col].fillna(df_clean[col].median())\n",
    "    \n",
    "    # Drop rows with missing Timestamp\n",
    "    df_clean = df_clean.dropna(subset=['Timestamp'])\n",
    "    \n",
    "    # Flag outliers (Z-scores > 3)\n",
    "    df_clean['outlier_flag'] = False\n",
    "    for col in CONFIG['numeric_cols']:\n",
    "        if col in df_clean.columns:\n",
    "            z_scores = np.abs(stats.zscore(df_clean[col]))\n",
    "            df_clean['outlier_flag'] |= (z_scores > 3)\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b886fe",
   "metadata": {},
   "source": [
    "Perform EDA function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ffd9c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_eda(df: pd.DataFrame, output_dir: str):\n",
    "    \"\"\"Perform EDA, generating visualizations for time series, correlations, wind, and relationships.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Cleaned dataset.\n",
    "        output_dir (str): Directory to save plots.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Time Series Plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for col in ['GHI', 'DNI', 'DHI', 'Tamb']:\n",
    "        if col in df.columns:\n",
    "            plt.plot(df['Timestamp'], df[col], label=col)\n",
    "    plt.title(f'Time Series of Irradiance and Temperature ({CONFIG[\"country\"].capitalize()})')\n",
    "    plt.xlabel('Timestamp')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{output_dir}/time_series_{CONFIG[\"country\"]}.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Correlation Heatmap\n",
    "    corr_cols = ['GHI', 'DNI', 'DHI', 'TModA', 'TModB']\n",
    "    if all(col in df.columns for col in corr_cols):\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(df[corr_cols].corr(), annot=True, cmap='coolwarm')\n",
    "        plt.title(f'Correlation Matrix ({CONFIG[\"country\"].capitalize()})')\n",
    "        plt.savefig(f'{output_dir}/correlation_heatmap_{CONFIG[\"country\"]}.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # Wind Rose\n",
    "    if 'WS' in df.columns and 'WD' in df.columns:\n",
    "        fig = plt.figure(figsize=(8, 8))\n",
    "        ax = WindroseAxes.from_ax(fig=fig)\n",
    "        ax.bar(df['WD'], df['WS'], normed=True, opening=0.8, edgecolor='white')\n",
    "        ax.set_legend()\n",
    "        plt.title(f'Wind Rose Plot ({CONFIG[\"country\"].capitalize()})')\n",
    "        plt.savefig(f'{output_dir}/wind_rose_{CONFIG[\"country\"]}.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # Bubble Chart (GHI vs Tamb, sized by RH)\n",
    "    if all(col in df.columns for col in ['GHI', 'Tamb', 'RH']):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(df['Tamb'], df['GHI'], s=df['RH']*10, c=df['RH'], cmap='viridis', alpha=0.5)\n",
    "        plt.colorbar(label='Relative Humidity (%)')\n",
    "        plt.xlabel('Ambient Temperature (°C)')\n",
    "        plt.ylabel('GHI (W/m²)')\n",
    "        plt.title(f'GHI vs Temperature (Bubble Size/Color by RH) ({CONFIG[\"country\"].capitalize()})')\n",
    "        plt.savefig(f'{output_dir}/bubble_chart_{CONFIG[\"country\"]}.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b205faa4",
   "metadata": {},
   "source": [
    "Main execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7e3944e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiling Results (Sierraleone):\n",
      "Statistics:\n",
      "                            Timestamp            GHI            DNI  \\\n",
      "count                         525600  525600.000000  525600.000000   \n",
      "mean   2022-04-30 12:00:30.000000768     201.957515     116.376337   \n",
      "min              2021-10-30 00:01:00     -19.500000      -7.800000   \n",
      "25%              2022-01-29 06:00:45      -2.800000      -0.300000   \n",
      "50%              2022-04-30 12:00:30       0.300000      -0.100000   \n",
      "75%              2022-07-30 18:00:15     362.400000     107.000000   \n",
      "max              2022-10-30 00:00:00    1499.000000     946.000000   \n",
      "std                              NaN     298.495150     218.652659   \n",
      "\n",
      "                 DHI           ModA           ModB           Tamb  \\\n",
      "count  525600.000000  525600.000000  525600.000000  525600.000000   \n",
      "mean      113.720571     206.643095     198.114691      26.319394   \n",
      "min       -17.900000       0.000000       0.000000      12.300000   \n",
      "25%        -3.800000       0.000000       0.000000      23.100000   \n",
      "50%        -0.100000       3.600000       3.400000      25.300000   \n",
      "75%       224.700000     359.500000     345.400000      29.400000   \n",
      "max       892.000000    1507.000000    1473.000000      39.900000   \n",
      "std       158.946032     300.896893     288.889073       4.398605   \n",
      "\n",
      "                  RH             WS         WSgust        WSstdev  \\\n",
      "count  525600.000000  525600.000000  525600.000000  525600.000000   \n",
      "mean       79.448857       1.146113       1.691606       0.363823   \n",
      "min         9.900000       0.000000       0.000000       0.000000   \n",
      "25%        68.700000       0.000000       0.000000       0.000000   \n",
      "50%        85.400000       0.800000       1.600000       0.400000   \n",
      "75%        96.700000       2.000000       2.600000       0.600000   \n",
      "max       100.000000      19.200000      23.900000       4.100000   \n",
      "std        20.520775       1.239248       1.617053       0.295000   \n",
      "\n",
      "                  WD        WDstdev             BP       Cleaning  \\\n",
      "count  525600.000000  525600.000000  525600.000000  525600.000000   \n",
      "mean      133.044668       7.172220     999.876469       0.000967   \n",
      "min         0.000000       0.000000     993.000000       0.000000   \n",
      "25%         0.000000       0.000000     999.000000       0.000000   \n",
      "50%       161.500000       6.200000    1000.000000       0.000000   \n",
      "75%       234.100000      12.000000    1001.000000       0.000000   \n",
      "max       360.000000      98.400000    1006.000000       1.000000   \n",
      "std       114.284792       7.535093       2.104419       0.031074   \n",
      "\n",
      "       Precipitation          TModA          TModB  Comments  \n",
      "count  525600.000000  525600.000000  525600.000000       0.0  \n",
      "mean        0.004806      32.504263      32.593091       NaN  \n",
      "min         0.000000      10.700000      11.100000       NaN  \n",
      "25%         0.000000      23.500000      23.800000       NaN  \n",
      "50%         0.000000      26.600000      26.900000       NaN  \n",
      "75%         0.000000      40.900000      41.300000       NaN  \n",
      "max         2.400000      72.800000      70.400000       NaN  \n",
      "std         0.047556      12.434899      12.009161       NaN  \n",
      "Missing Values:\n",
      " Timestamp             0\n",
      "GHI                   0\n",
      "DNI                   0\n",
      "DHI                   0\n",
      "ModA                  0\n",
      "ModB                  0\n",
      "Tamb                  0\n",
      "RH                    0\n",
      "WS                    0\n",
      "WSgust                0\n",
      "WSstdev               0\n",
      "WD                    0\n",
      "WDstdev               0\n",
      "BP                    0\n",
      "Cleaning              0\n",
      "Precipitation         0\n",
      "TModA                 0\n",
      "TModB                 0\n",
      "Comments         525600\n",
      "dtype: int64\n",
      "Negative Counts:\n",
      " {'GHI': np.int64(261135), 'DNI': np.int64(266352), 'DHI': np.int64(263128), 'ModA': np.int64(0), 'ModB': np.int64(0)}\n",
      "Outlier Counts:\n",
      " {'GHI': np.int64(2477), 'DNI': np.int64(7586), 'DHI': np.int64(2986), 'ModA': np.int64(1604), 'ModB': np.int64(2041), 'Tamb': np.int64(192), 'RH': np.int64(4929), 'WS': np.int64(3967), 'WSgust': np.int64(3665), 'WD': np.int64(0), 'TModA': np.int64(100), 'TModB': np.int64(4)}\n",
      "EDA completed for Sierraleone. Outputs saved in data/ directory.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Execute the EDA pipeline for the configured dataset.\"\"\"\n",
    "    try:\n",
    "        # Load data\n",
    "        df = load_data(CONFIG['raw_data_file'])\n",
    "        \n",
    "        # Profile data\n",
    "        profile = profile_data(df)\n",
    "        print(f\"Profiling Results ({CONFIG['country'].capitalize()}):\")\n",
    "        print(\"Statistics:\\n\", profile['statistics'])\n",
    "        print(\"Missing Values:\\n\", profile['missing_counts'])\n",
    "        print(\"Negative Counts:\\n\", profile['negative_counts'])\n",
    "        print(\"Outlier Counts:\\n\", profile['outlier_counts'])\n",
    "        \n",
    "        # Clean data\n",
    "        df_clean = clean_data(df)\n",
    "        \n",
    "        # Save cleaned data\n",
    "        os.makedirs(os.path.dirname(CONFIG['cleaned_data_file']), exist_ok=True)\n",
    "        df_clean.to_csv(CONFIG['cleaned_data_file'], index=False)\n",
    "        \n",
    "        # Perform EDA\n",
    "        perform_eda(df_clean, 'data/SIERRALEONE-plots')\n",
    "        \n",
    "        print(f\"EDA completed for {CONFIG['country'].capitalize()}. Outputs saved in data/ directory.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "\n",
    "# Run the pipeline\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
